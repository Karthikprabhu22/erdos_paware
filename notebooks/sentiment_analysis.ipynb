{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Notebook\n",
    "\n",
    "This Jupyter notebook is used for sentiment analysis. It uses several libraries to perform this task:\n",
    "\n",
    "1. `polars`\n",
    "2. `numpy`\n",
    "3. `transformers`\n",
    "\n",
    "The notebook imports the following modules from the `transformers` library:\n",
    "\n",
    "- `pipeline`: This is a high-level, easy to use, API for doing end-to-end NLP tasks.\n",
    "\n",
    "- `AutoTokenizer`: This class can automatically choose the correct tokenizer for the model specified.\n",
    "\n",
    "- `AutoModelForTokenClassification`: This class can automatically choose the correct model for token classification tasks.\n",
    "\n",
    "Please ensure that all these libraries are installed in your Python environment before running this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "from transformers import pipeline,AutoTokenizer, AutoModelForTokenClassification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet('../../reddit_subset_gm.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_reply_list(df:pl.DataFrame)->pl.DataFrame:\n",
    "    '''\n",
    "    A function that adds a column called 'reply_ids' that contains a list of the \n",
    "    'reddit_name' ids that are replies to the post in that row. If a there are \n",
    "    no replies, the value in this column is 'null'.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        df:pl.DataFrame\n",
    "            A pl.DataFrame with a schema similar to the raw Aware data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "        pl.DataFrame\n",
    "            The input dataframe along with a new 'reply_ids' column, as \n",
    "            described above.\n",
    "    '''\n",
    "\n",
    "    ## Group the data by 'reddit_parent_id'\n",
    "    group = df.group_by(\"reddit_parent_id\")\n",
    "\n",
    "    ## Aggregate the list of 'reddit_names' for each 'reddit_parent_id'\n",
    "    replies = group.agg(pl.col(\"reddit_name\"))\n",
    "    ## Rename the columns so that they are aligned for joining. \n",
    "    ## We want to add the list of replies to a 'reddit_parent_id' to the\n",
    "    ## row whose 'reddit_name' matches that value.\n",
    "    new_names = {\"reddit_name\":\"reply_ids\",\"reddit_parent_id\":\"reddit_name\"}\n",
    "    replies = replies.rename(new_names)\n",
    "\n",
    "    ## Join the list of 'reddit_name' values that are replies\n",
    "    return df.join(replies, on=\"reddit_name\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Function\n",
    "\n",
    "This cell defines two functions: `load_sentiment_model` and `get_sentiment_list`.\n",
    "\n",
    "## load_sentiment_model Function\n",
    "\n",
    "This function loads a pre-trained sentiment analysis model and its tokenizer from the Hugging Face model hub. The model used is \"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\", a DistilRoBERTa model fine-tuned for financial news sentiment analysis. The function returns a pipeline object that can be used for Named Entity Recognition (NER), which in this context is used for sentiment analysis.\n",
    "\n",
    "## get_sentiment_list Function\n",
    "\n",
    "This function takes a list of texts as input. It first loads the sentiment analysis model and tokenizer using the `load_sentiment_model` function. It then processes each text in the input list with the model, extracting the sentiment from the results. If no sentiment is detected, it defaults to 'No Sentiment Detected'. The function returns a list of tuples, where each tuple contains the original text and its detected sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sentiment_model():\n",
    "    # Load the tokenizer and model once to reuse for multiple calls\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
    "    nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "    return nlp\n",
    "\n",
    "def get_sentiment_list(texts):\n",
    "    # Load the NLP model and tokenizer once\n",
    "    nlp = load_sentiment_model()\n",
    "    \n",
    "    # List to hold the sentiment results\n",
    "    results_list = []\n",
    "    \n",
    "    # Process each text in the list\n",
    "    for text in texts:\n",
    "        results = nlp(text)\n",
    "        sentiment = results[0]['entity'] if results else 'No Sentiment Detected'\n",
    "        results_list.append((text, sentiment))\n",
    "    \n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_replies = add_reply_list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Easier now too. Ten years ago GM was handing out serious lowball offers coming out of the Great Recession and bankruptcy.\n",
      "\n",
      "EDIT Why am I being downvoted for this? It's true. Ask anybody hired in 2013 what they got as a starting salary. TRACK engineers were below $60k for a while. Anyone thinking things are worse now than in the years after bankruptcy is dumb as fuck.\n",
      "Number of replies to this comment:  4\n"
     ]
    }
   ],
   "source": [
    "# Pick out a random post which has a few replies\n",
    "randint=612\n",
    "example_reddit_names = df_with_replies[randint][\"reply_ids\"]\n",
    "example_replies = df.filter(pl.col(\"reddit_name\").is_in(example_reddit_names[0]))[\"reddit_text\"]\n",
    "print(df_with_replies[randint][\"reddit_text\"][0])\n",
    "print(\"Number of replies to this comment: \", df_with_replies[randint][\"reply_ids\"][0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('This is true. If you work at a tech center or are a developer, you make more hopping companies. If you work at an area with a plant in engineering, other manufacturers pay $20k+ LESS, or they pay the same with half the vacation and benefits.',\n",
       "  'positive'),\n",
       " ('i got a great offer ens of 2012, so it likely varies by area.', 'positive'),\n",
       " ('I was hired in 2014 and itâ€™s true. I made $73k with 4 years of experience. It took leaving and coming back to get my salary on track. If I stayed the whole time I doubt very much I would have jumped up the way I did.',\n",
       "  'positive'),\n",
       " ('Do you ever hear people talk about how Twitter is not an accurate representation of real people? Well GM reddit has an unhealthy balance of employees who hate GM with a passion. Its weird.',\n",
       "  'positive')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_list(example_replies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
