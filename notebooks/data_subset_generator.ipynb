{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a27048a-1316-4c69-b9dd-b0358b720a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "import pyarrow as pa\n",
    "from typing import List\n",
    "\n",
    "TEMP_DATA_DIR = \"../temp_data/\"\n",
    "RAW_DATA = pl.read_parquet(\"../reddit_data/reddit.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e079bc8e-83ca-4b78-92a3-e0630416cedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (34, 2)\n",
      "┌─────────────────────┬────────┐\n",
      "│ reddit_subreddit    ┆ count  │\n",
      "│ ---                 ┆ ---    │\n",
      "│ str                 ┆ u32    │\n",
      "╞═════════════════════╪════════╡\n",
      "│ CVS                 ┆ 179598 │\n",
      "│ Bestbuy             ┆ 121077 │\n",
      "│ disney              ┆ 43954  │\n",
      "│ PaneraEmployees     ┆ 2694   │\n",
      "│ WalmartEmployees    ┆ 10752  │\n",
      "│ DisneyWorld         ┆ 65549  │\n",
      "│ Disneyland          ┆ 231981 │\n",
      "│ Target              ┆ 340401 │\n",
      "│ TalesFromYourBank   ┆ 28444  │\n",
      "│ DollarTree          ┆ 59745  │\n",
      "│ starbucks           ┆ 393597 │\n",
      "│ nursing             ┆ 789499 │\n",
      "│ walmart             ┆ 630962 │\n",
      "│ wholefoods          ┆ 82052  │\n",
      "│ GeneralMotors       ┆ 37277  │\n",
      "│ TjMaxx              ┆ 46286  │\n",
      "│ Chase               ┆ 16931  │\n",
      "│ cybersecurity       ┆ 161868 │\n",
      "│ KrakenSupport       ┆ 14533  │\n",
      "│ McLounge            ┆ 38627  │\n",
      "│ UPSers              ┆ 262483 │\n",
      "│ cabincrewcareers    ┆ 23408  │\n",
      "│ Lowes               ┆ 198805 │\n",
      "│ fidelityinvestments ┆ 129423 │\n",
      "│ sysadmin            ┆ 557558 │\n",
      "│ BestBuyWorkers      ┆ 5629   │\n",
      "│ starbucksbaristas   ┆ 132019 │\n",
      "│ Fedexers            ┆ 154572 │\n",
      "│ WaltDisneyWorld     ┆ 373138 │\n",
      "│ McDonaldsEmployees  ┆ 174679 │\n",
      "│ RiteAid             ┆ 3970   │\n",
      "│ GameStop            ┆ 137071 │\n",
      "│ FedEmployees        ┆ 280    │\n",
      "│ Panera              ┆ 79436  │\n",
      "└─────────────────────┴────────┘\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.Config.set_tbl_rows(40)\n",
    "print(RAW_DATA[\"reddit_subreddit\"].value_counts())\n",
    "pl.Config.set_tbl_rows(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f0b1ac5-feb9-48d9-97ee-f6ee2a220715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subset_parquet(RAW_DATA:pl.DataFrame,\n",
    "                            subreddits: List[str], \n",
    "                            filename: str,\n",
    "                            overwrite: bool=False)->None:\n",
    "    '''\n",
    "        Generate a parquete containing only the data for the specified \n",
    "        subreddits. Will be saved at \"TEMP_DATA_DIR/[filename]\"\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "            raw_data: pl.DataFrame\n",
    "                A dataframe containing all of the raw data\n",
    "            subreddits: List[str]\n",
    "                A list of subreddits to include in the subset\n",
    "                E.g.: [\"starbucks\", \"Chase\"]\n",
    "            filename: str\n",
    "                The filename to save the subset of data to. \n",
    "                E.g.: \"raw_data_gm.parquet\"\n",
    "                \n",
    "        Returns:\n",
    "        --------\n",
    "            None\n",
    "    '''\n",
    "    file_exists = os.path.exists(TEMP_DATA_DIR+filename)\n",
    "    if file_exists and not overwrite:\n",
    "        print(\"File already exists. To overwrite, set 'overwrite=True'\")\n",
    "    else:\n",
    "        data_subset = RAW_DATA.filter(\n",
    "            pl.col(\"reddit_subreddit\").is_in(subreddits))\n",
    "        data_subset.write_parquet(TEMP_DATA_DIR+filename)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0af799-5137-48ed-b326-7289ad8eeb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_subset_parquet(RAW_DATA=RAW_DATA, \n",
    "                        subreddits=[\"starbucks\", \"Chase\"], \n",
    "                        filename=\"raw_data_subset_starbucks_chase.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aware] *",
   "language": "python",
   "name": "conda-env-aware-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
